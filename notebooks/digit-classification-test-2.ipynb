{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b516e70-29ca-42d2-8ac6-6ddcfa7181c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn, sklearn.linear_model, sklearn.multiclass, sklearn.naive_bayes\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a106a25-12f1-419e-b881-0c4842d7eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f0055-6d15-4fa9-8e3c-316f791a99e1",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53bc81c-d6d3-43e6-a257-de555bd6da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('drawings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54db045d-231a-4515-bc46-87ecde0adbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5517 entries, 0 to 5516\n",
      "Columns: 785 entries, 0 to label\n",
      "dtypes: int64(785)\n",
      "memory usage: 33.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7362b65-6185-4999-9dd1-54c6f44380ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  label  \n",
       "0    0      0  \n",
       "1    0      0  \n",
       "2    0      0  \n",
       "3    0      0  \n",
       "4    0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57dcf1c7-4902-440f-89de-9273f055c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data.iloc[:, :-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8ded99-5e95-4989-a317-c87c3f601ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b71c29-1db3-4e77-a125-dc9e76dc72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(len(images), 28,  28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efeb4acb-c828-4c6c-82c3-97dd07c9450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5517, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3c6a9-33a6-4339-b4fe-dc87cc668cfd",
   "metadata": {},
   "source": [
    "### Plotting Images And Corresponding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afabc991-dbf6-4863-87e8-c0c0c2b2aab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows, cols = 5, 5\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols)\n",
    "\n",
    "indices = np.random.choice(len(images), rows * cols)\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        axes[i, j].imshow(images[indices[counter]])\n",
    "        axes[i, j].set_title(f\"Label: {labels[indices[counter]]}\")\n",
    "        axes[i, j].set_xticks([])\n",
    "        axes[i, j].set_yticks([])\n",
    "        counter += 1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee5972a-da7e-425e-87fa-a7ba2b4ec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35acf443-8437-48f4-8799-4cd21fe9418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89651c41-2826-4fe6-99f6-a6c0e8156524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (4413, 28, 28, 1)\n",
      "Test images shape: (1104, 28, 28, 1)\n",
      "Train labels shape: (4413, 10)\n",
      "Test labels shape: (1104, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train images shape: {train_images.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181cbf7c-79fe-4faf-92a8-ed8e0c5fb8c5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c15736-3657-4e09-8ccf-5184d1e3a0ff",
   "metadata": {},
   "source": [
    "### Training On Drawn Images And Validating On The MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0211d43-d0b2-4afe-a976-600c06d7c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995b24ab-00a5-450b-970c-50a6dcc81f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr=0.001):\n",
    "    model = Sequential([\n",
    "        layers.Conv2D(64, 5, activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPool2D(2),\n",
    "        layers.Conv2D(128, 5, activation='relu'),\n",
    "        layers.MaxPool2D(2),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd1aa18-1dc0-43ac-904e-b0bdec37bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92414cf3-b8f1-4f69-874b-3d581cc317fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 207,882\n",
      "Trainable params: 207,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a2dda29-2c90-4b31-b6f3-aa023e49f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.3,\n",
    "                                                           height_shift_range=0.10,\n",
    "                                                           width_shift_range=0.10,\n",
    "                                                           rotation_range=10)\n",
    "\n",
    "train_datagen = train_gen.flow(train_images, train_labels, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98f94685-e6fd-4b50-92ba-81e701e2a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 4s 73ms/step - loss: 2.2157 - accuracy: 0.2042 - val_loss: 2.0458 - val_accuracy: 0.3995\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 1.8779 - accuracy: 0.4283 - val_loss: 1.4283 - val_accuracy: 0.6096\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 1.4201 - accuracy: 0.5663 - val_loss: 0.9167 - val_accuracy: 0.8071\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 1.1157 - accuracy: 0.6646 - val_loss: 0.7222 - val_accuracy: 0.8442\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.9413 - accuracy: 0.7154 - val_loss: 0.5652 - val_accuracy: 0.8433\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.8156 - accuracy: 0.7544 - val_loss: 0.5778 - val_accuracy: 0.8188\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.7207 - accuracy: 0.7804 - val_loss: 0.3851 - val_accuracy: 0.9085\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.6349 - accuracy: 0.8149 - val_loss: 0.3597 - val_accuracy: 0.9103\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.5808 - accuracy: 0.8414 - val_loss: 0.3039 - val_accuracy: 0.9275\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.5353 - accuracy: 0.8511 - val_loss: 0.2889 - val_accuracy: 0.9303\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.5028 - accuracy: 0.8534 - val_loss: 0.2733 - val_accuracy: 0.9393\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.4582 - accuracy: 0.8697 - val_loss: 0.2157 - val_accuracy: 0.9547\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.4366 - accuracy: 0.8806 - val_loss: 0.2224 - val_accuracy: 0.9484\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.4080 - accuracy: 0.8881 - val_loss: 0.1766 - val_accuracy: 0.9620\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3986 - accuracy: 0.8896 - val_loss: 0.1737 - val_accuracy: 0.9565\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3671 - accuracy: 0.9003 - val_loss: 0.1776 - val_accuracy: 0.9529\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.3528 - accuracy: 0.8989 - val_loss: 0.1648 - val_accuracy: 0.9620\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3503 - accuracy: 0.9048 - val_loss: 0.1415 - val_accuracy: 0.9683\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.3221 - accuracy: 0.9114 - val_loss: 0.1245 - val_accuracy: 0.9764\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.2865 - accuracy: 0.9236 - val_loss: 0.1185 - val_accuracy: 0.9774\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2794 - accuracy: 0.9245 - val_loss: 0.1176 - val_accuracy: 0.9755\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.2832 - accuracy: 0.9211 - val_loss: 0.1266 - val_accuracy: 0.9719\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.2692 - accuracy: 0.9264 - val_loss: 0.1138 - val_accuracy: 0.9746\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.2618 - accuracy: 0.9254 - val_loss: 0.1090 - val_accuracy: 0.9755\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2594 - accuracy: 0.9295 - val_loss: 0.1070 - val_accuracy: 0.9746\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.2521 - accuracy: 0.9325 - val_loss: 0.1068 - val_accuracy: 0.9774\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.2570 - accuracy: 0.9282 - val_loss: 0.1077 - val_accuracy: 0.9683\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.2357 - accuracy: 0.9336 - val_loss: 0.1032 - val_accuracy: 0.9755\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2425 - accuracy: 0.9322 - val_loss: 0.1052 - val_accuracy: 0.9719\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.2271 - accuracy: 0.9377 - val_loss: 0.0928 - val_accuracy: 0.9792\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2228 - accuracy: 0.9397 - val_loss: 0.0936 - val_accuracy: 0.9783\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2175 - accuracy: 0.9395 - val_loss: 0.0829 - val_accuracy: 0.9783\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.2121 - accuracy: 0.9409 - val_loss: 0.0850 - val_accuracy: 0.9774\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2057 - accuracy: 0.9461 - val_loss: 0.0985 - val_accuracy: 0.9728\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.2229 - accuracy: 0.9338 - val_loss: 0.0826 - val_accuracy: 0.9755\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2062 - accuracy: 0.9377 - val_loss: 0.0812 - val_accuracy: 0.9774\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1972 - accuracy: 0.9418 - val_loss: 0.0753 - val_accuracy: 0.9774\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1711 - accuracy: 0.9526 - val_loss: 0.0807 - val_accuracy: 0.9783\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1943 - accuracy: 0.9400 - val_loss: 0.0771 - val_accuracy: 0.9810\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1722 - accuracy: 0.9499 - val_loss: 0.0688 - val_accuracy: 0.9801\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1810 - accuracy: 0.9490 - val_loss: 0.0679 - val_accuracy: 0.9846\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1589 - accuracy: 0.9524 - val_loss: 0.0715 - val_accuracy: 0.9810\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.1656 - accuracy: 0.9545 - val_loss: 0.0733 - val_accuracy: 0.9819\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1654 - accuracy: 0.9517 - val_loss: 0.0761 - val_accuracy: 0.9801\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 1s 64ms/step - loss: 0.1693 - accuracy: 0.9483 - val_loss: 0.0779 - val_accuracy: 0.9755\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1634 - accuracy: 0.9513 - val_loss: 0.0657 - val_accuracy: 0.9855\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 1s 66ms/step - loss: 0.1577 - accuracy: 0.9538 - val_loss: 0.0641 - val_accuracy: 0.9819\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1461 - accuracy: 0.9594 - val_loss: 0.0657 - val_accuracy: 0.9864\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1538 - accuracy: 0.9535 - val_loss: 0.0610 - val_accuracy: 0.9837\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1617 - accuracy: 0.9549 - val_loss: 0.0639 - val_accuracy: 0.9846\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1473 - accuracy: 0.9572 - val_loss: 0.0673 - val_accuracy: 0.9873\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1433 - accuracy: 0.9554 - val_loss: 0.0640 - val_accuracy: 0.9846\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1390 - accuracy: 0.9613 - val_loss: 0.0568 - val_accuracy: 0.9855\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1472 - accuracy: 0.9565 - val_loss: 0.0606 - val_accuracy: 0.9828\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1422 - accuracy: 0.9603 - val_loss: 0.0567 - val_accuracy: 0.9819\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.1364 - accuracy: 0.9597 - val_loss: 0.0531 - val_accuracy: 0.9855\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1380 - accuracy: 0.9615 - val_loss: 0.0644 - val_accuracy: 0.9801\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1344 - accuracy: 0.9619 - val_loss: 0.0597 - val_accuracy: 0.9837\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1369 - accuracy: 0.9599 - val_loss: 0.0555 - val_accuracy: 0.9864\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1397 - accuracy: 0.9592 - val_loss: 0.0567 - val_accuracy: 0.9828\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.1407 - accuracy: 0.9606 - val_loss: 0.0538 - val_accuracy: 0.9828\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1338 - accuracy: 0.9649 - val_loss: 0.0632 - val_accuracy: 0.9828\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1349 - accuracy: 0.9617 - val_loss: 0.0598 - val_accuracy: 0.9819\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1214 - accuracy: 0.9671 - val_loss: 0.0509 - val_accuracy: 0.9828\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1215 - accuracy: 0.9640 - val_loss: 0.0511 - val_accuracy: 0.9873\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1141 - accuracy: 0.9678 - val_loss: 0.0646 - val_accuracy: 0.9837\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1204 - accuracy: 0.9665 - val_loss: 0.0540 - val_accuracy: 0.9855\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1298 - accuracy: 0.9610 - val_loss: 0.0665 - val_accuracy: 0.9810\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 1s 63ms/step - loss: 0.1202 - accuracy: 0.9622 - val_loss: 0.0528 - val_accuracy: 0.9855\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.1215 - accuracy: 0.9656 - val_loss: 0.0435 - val_accuracy: 0.9891\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.1080 - accuracy: 0.9701 - val_loss: 0.0477 - val_accuracy: 0.9855\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1140 - accuracy: 0.9671 - val_loss: 0.0497 - val_accuracy: 0.9846\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1012 - accuracy: 0.9703 - val_loss: 0.0509 - val_accuracy: 0.9873\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1024 - accuracy: 0.9733 - val_loss: 0.0448 - val_accuracy: 0.9882\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1082 - accuracy: 0.9658 - val_loss: 0.0514 - val_accuracy: 0.9846\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1041 - accuracy: 0.9687 - val_loss: 0.0526 - val_accuracy: 0.9855\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1144 - accuracy: 0.9640 - val_loss: 0.0519 - val_accuracy: 0.9819\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1038 - accuracy: 0.9705 - val_loss: 0.0446 - val_accuracy: 0.9891\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1034 - accuracy: 0.9676 - val_loss: 0.0504 - val_accuracy: 0.9846\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1058 - accuracy: 0.9701 - val_loss: 0.0547 - val_accuracy: 0.9846\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.0991 - accuracy: 0.9719 - val_loss: 0.0497 - val_accuracy: 0.9864\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1016 - accuracy: 0.9678 - val_loss: 0.0441 - val_accuracy: 0.9900\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0998 - accuracy: 0.9714 - val_loss: 0.0726 - val_accuracy: 0.9819\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1093 - accuracy: 0.9703 - val_loss: 0.0547 - val_accuracy: 0.9837\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0985 - accuracy: 0.9733 - val_loss: 0.0494 - val_accuracy: 0.9882\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.1053 - accuracy: 0.9683 - val_loss: 0.0486 - val_accuracy: 0.9882\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1032 - accuracy: 0.9701 - val_loss: 0.0379 - val_accuracy: 0.9918\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0808 - accuracy: 0.9796 - val_loss: 0.0474 - val_accuracy: 0.9864\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1008 - accuracy: 0.9694 - val_loss: 0.0440 - val_accuracy: 0.9891\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1000 - accuracy: 0.9712 - val_loss: 0.0673 - val_accuracy: 0.9810\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0985 - accuracy: 0.9690 - val_loss: 0.0435 - val_accuracy: 0.9891\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0835 - accuracy: 0.9773 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0845 - accuracy: 0.9742 - val_loss: 0.0399 - val_accuracy: 0.9900\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0804 - accuracy: 0.9782 - val_loss: 0.0436 - val_accuracy: 0.9891\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0822 - accuracy: 0.9787 - val_loss: 0.0546 - val_accuracy: 0.9846\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0937 - accuracy: 0.9730 - val_loss: 0.0488 - val_accuracy: 0.9882\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0926 - accuracy: 0.9721 - val_loss: 0.0475 - val_accuracy: 0.9891\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0837 - accuracy: 0.9744 - val_loss: 0.0468 - val_accuracy: 0.9846\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0800 - accuracy: 0.9782 - val_loss: 0.0454 - val_accuracy: 0.9873\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0735 - accuracy: 0.9798 - val_loss: 0.0375 - val_accuracy: 0.9918\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0816 - accuracy: 0.9764 - val_loss: 0.0352 - val_accuracy: 0.9882\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.0720 - accuracy: 0.9792 - val_loss: 0.0402 - val_accuracy: 0.9891\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.0734 - accuracy: 0.9782 - val_loss: 0.0389 - val_accuracy: 0.9909\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0856 - accuracy: 0.9737 - val_loss: 0.0509 - val_accuracy: 0.9855\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0994 - accuracy: 0.9694 - val_loss: 0.0491 - val_accuracy: 0.9882\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0941 - accuracy: 0.9710 - val_loss: 0.0481 - val_accuracy: 0.9891\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.0782 - accuracy: 0.9785 - val_loss: 0.0443 - val_accuracy: 0.9864\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0864 - accuracy: 0.9762 - val_loss: 0.0334 - val_accuracy: 0.9909\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0755 - accuracy: 0.9776 - val_loss: 0.0398 - val_accuracy: 0.9882\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0826 - accuracy: 0.9753 - val_loss: 0.0340 - val_accuracy: 0.9918\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0818 - accuracy: 0.9753 - val_loss: 0.0363 - val_accuracy: 0.9900\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.0750 - accuracy: 0.9792 - val_loss: 0.0358 - val_accuracy: 0.9918\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0639 - accuracy: 0.9821 - val_loss: 0.0392 - val_accuracy: 0.9918\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0777 - accuracy: 0.9780 - val_loss: 0.0433 - val_accuracy: 0.9909\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0729 - accuracy: 0.9812 - val_loss: 0.0387 - val_accuracy: 0.9900\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0700 - accuracy: 0.9785 - val_loss: 0.0497 - val_accuracy: 0.9864\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0656 - accuracy: 0.9828 - val_loss: 0.0377 - val_accuracy: 0.9900\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0769 - accuracy: 0.9785 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 0.0400 - val_accuracy: 0.9891\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0678 - accuracy: 0.9798 - val_loss: 0.0321 - val_accuracy: 0.9891\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0801 - accuracy: 0.9789 - val_loss: 0.0386 - val_accuracy: 0.9909\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0704 - accuracy: 0.9787 - val_loss: 0.0331 - val_accuracy: 0.9918\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 0.0332 - val_accuracy: 0.9928\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0683 - accuracy: 0.9821 - val_loss: 0.0374 - val_accuracy: 0.9873\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0706 - accuracy: 0.9773 - val_loss: 0.0314 - val_accuracy: 0.9937\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0339 - val_accuracy: 0.9891\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0660 - accuracy: 0.9812 - val_loss: 0.0365 - val_accuracy: 0.9928\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0598 - accuracy: 0.9837 - val_loss: 0.0346 - val_accuracy: 0.9909\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 1s 63ms/step - loss: 0.0651 - accuracy: 0.9812 - val_loss: 0.0371 - val_accuracy: 0.9900\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0696 - accuracy: 0.9780 - val_loss: 0.0352 - val_accuracy: 0.9928\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0610 - accuracy: 0.9832 - val_loss: 0.0313 - val_accuracy: 0.9909\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0630 - accuracy: 0.9819 - val_loss: 0.0334 - val_accuracy: 0.9900\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.0382 - val_accuracy: 0.9909\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0597 - accuracy: 0.9826 - val_loss: 0.0370 - val_accuracy: 0.9909\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0688 - accuracy: 0.9801 - val_loss: 0.0299 - val_accuracy: 0.9909\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0645 - accuracy: 0.9812 - val_loss: 0.0362 - val_accuracy: 0.9900\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.0641 - accuracy: 0.9826 - val_loss: 0.0288 - val_accuracy: 0.9928\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.0649 - accuracy: 0.9803 - val_loss: 0.0321 - val_accuracy: 0.9918\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0603 - accuracy: 0.9839 - val_loss: 0.0366 - val_accuracy: 0.9909\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0658 - accuracy: 0.9798 - val_loss: 0.0456 - val_accuracy: 0.9909\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0747 - accuracy: 0.9767 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0639 - accuracy: 0.9828 - val_loss: 0.0342 - val_accuracy: 0.9909\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0677 - accuracy: 0.9801 - val_loss: 0.0336 - val_accuracy: 0.9937\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0534 - accuracy: 0.9841 - val_loss: 0.0321 - val_accuracy: 0.9928\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0565 - accuracy: 0.9848 - val_loss: 0.0402 - val_accuracy: 0.9891\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0640 - accuracy: 0.9823 - val_loss: 0.0337 - val_accuracy: 0.9900\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0632 - accuracy: 0.9816 - val_loss: 0.0319 - val_accuracy: 0.9928\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0666 - accuracy: 0.9826 - val_loss: 0.0340 - val_accuracy: 0.9928\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0609 - accuracy: 0.9805 - val_loss: 0.0294 - val_accuracy: 0.9928\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0514 - accuracy: 0.9853 - val_loss: 0.0405 - val_accuracy: 0.9882\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.0379 - val_accuracy: 0.9909\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0596 - accuracy: 0.9823 - val_loss: 0.0332 - val_accuracy: 0.9900\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0601 - accuracy: 0.9837 - val_loss: 0.0314 - val_accuracy: 0.9918\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.0354 - val_accuracy: 0.9891\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0493 - accuracy: 0.9862 - val_loss: 0.0403 - val_accuracy: 0.9882\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0483 - accuracy: 0.9862 - val_loss: 0.0311 - val_accuracy: 0.9937\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.0433 - val_accuracy: 0.9900\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0698 - accuracy: 0.9782 - val_loss: 0.0424 - val_accuracy: 0.9900\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0571 - accuracy: 0.9828 - val_loss: 0.0355 - val_accuracy: 0.9937\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 0.0382 - val_accuracy: 0.9891\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0558 - accuracy: 0.9816 - val_loss: 0.0412 - val_accuracy: 0.9891\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0334 - val_accuracy: 0.9918\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0687 - accuracy: 0.9780 - val_loss: 0.0377 - val_accuracy: 0.9918\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0625 - accuracy: 0.9821 - val_loss: 0.0343 - val_accuracy: 0.9900\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0534 - accuracy: 0.9853 - val_loss: 0.0385 - val_accuracy: 0.9928\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0486 - accuracy: 0.9864 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.0494 - accuracy: 0.9850 - val_loss: 0.0267 - val_accuracy: 0.9928\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0502 - accuracy: 0.9864 - val_loss: 0.0306 - val_accuracy: 0.9937\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.0347 - val_accuracy: 0.9918\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 0.0306 - val_accuracy: 0.9937\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0499 - accuracy: 0.9830 - val_loss: 0.0352 - val_accuracy: 0.9928\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0502 - accuracy: 0.9860 - val_loss: 0.0320 - val_accuracy: 0.9928\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0474 - accuracy: 0.9871 - val_loss: 0.0310 - val_accuracy: 0.9946\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.0599 - accuracy: 0.9819 - val_loss: 0.0253 - val_accuracy: 0.9946\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.0274 - val_accuracy: 0.9946\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0399 - val_accuracy: 0.9891\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0521 - accuracy: 0.9862 - val_loss: 0.0323 - val_accuracy: 0.9937\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.0336 - val_accuracy: 0.9937\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0424 - accuracy: 0.9882 - val_loss: 0.0394 - val_accuracy: 0.9900\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0451 - accuracy: 0.9853 - val_loss: 0.0283 - val_accuracy: 0.9955\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.0288 - val_accuracy: 0.9946\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0549 - accuracy: 0.9837 - val_loss: 0.0303 - val_accuracy: 0.9928\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0446 - accuracy: 0.9889 - val_loss: 0.0300 - val_accuracy: 0.9928\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 0.0374 - val_accuracy: 0.9909\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0405 - accuracy: 0.9882 - val_loss: 0.0305 - val_accuracy: 0.9928\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0457 - accuracy: 0.9862 - val_loss: 0.0249 - val_accuracy: 0.9937\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0440 - accuracy: 0.9860 - val_loss: 0.0294 - val_accuracy: 0.9928\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0447 - accuracy: 0.9880 - val_loss: 0.0384 - val_accuracy: 0.9900\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0489 - accuracy: 0.9862 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0428 - accuracy: 0.9875 - val_loss: 0.0328 - val_accuracy: 0.9928\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.0368 - accuracy: 0.9893 - val_loss: 0.0294 - val_accuracy: 0.9937\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 0.0311 - val_accuracy: 0.9937\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0530 - accuracy: 0.9853 - val_loss: 0.0338 - val_accuracy: 0.9909\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.0325 - val_accuracy: 0.9909\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0346 - accuracy: 0.9893 - val_loss: 0.0339 - val_accuracy: 0.9955\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 0.0274 - val_accuracy: 0.9946\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0439 - accuracy: 0.9855 - val_loss: 0.0305 - val_accuracy: 0.9937\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0400 - accuracy: 0.9891 - val_loss: 0.0318 - val_accuracy: 0.9937\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0459 - accuracy: 0.9871 - val_loss: 0.0351 - val_accuracy: 0.9937\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.0322 - val_accuracy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a0b0e39a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_datagen, initial_epoch=0, epochs=200,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643031d-ce98-49f5-8fdd-656e310b6610",
   "metadata": {},
   "source": [
    "#### Evaluating on drawn test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77f64793-b41e-47af-ae58-3519ca109005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.032215896993875504, 0.9909420013427734]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d81997a-0b6f-4fc4-ac32-8cf61c62ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "008835c9-3238-4aff-a6ae-36aaf88392ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_images = mnist_train_images.reshape(len(mnist_train_images), 28, 28, 1) / 255.0\n",
    "mnist_test_images = mnist_test_images.reshape(len(mnist_test_images), 28, 28, 1) / 255.0         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c839a4-9ad0-4149-a683-1eede6ddb0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6efacc59-6a06-49d5-a111-f4b50153335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "705b1195-8b3f-45d5-a48b-aa56bf4faff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_labels = tf.keras.utils.to_categorical(mnist_train_labels)\n",
    "mnist_test_labels = tf.keras.utils.to_categorical(mnist_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14e1ea2b-f931-42e7-8665-e34da85c0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_images, mnist_labels = np.concatenate((mnist_train_images, mnist_test_images)), np.concatenate((mnist_train_labels, mnist_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "621b9d2d-bcb1-4b46-b667-e2237cf9bc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 28, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2be7daf-49ad-46cb-ad7b-087bf27eed69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc76172-42e2-4f79-a9bc-18808b4a669d",
   "metadata": {},
   "source": [
    "#### Evaluating on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "599bb7ff-6e9e-432e-a40a-dbefce1b2f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - 7s 3ms/step - loss: 0.5623 - accuracy: 0.8545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5623145699501038, 0.8545143008232117]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist_images, mnist_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0456c10c-6c4c-4e44-b896-af4713482a38",
   "metadata": {},
   "source": [
    "### Training On MNIST Images And Validating On Drawn Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a71f9d-fbe7-4bc9-8403-5f5f7dd8aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65fabf5f-df21-4e40-9bc8-be54820704a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.3,\n",
    "                                                           height_shift_range=0.10,\n",
    "                                                           width_shift_range=0.10,\n",
    "                                                           rotation_range=10)\n",
    "\n",
    "train_datagen = train_gen.flow(mnist_train_images, mnist_train_labels, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cfcfdf2-8f1a-4665-a0c2-f4143b1ef0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "235/235 [==============================] - 14s 60ms/step - loss: 1.0747 - accuracy: 0.6671 - val_loss: 0.3183 - val_accuracy: 0.9175\n",
      "Epoch 2/30\n",
      "235/235 [==============================] - 14s 60ms/step - loss: 0.4522 - accuracy: 0.8707 - val_loss: 0.1641 - val_accuracy: 0.9573\n",
      "Epoch 3/30\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.3449 - accuracy: 0.9001 - val_loss: 0.1317 - val_accuracy: 0.9628\n",
      "Epoch 4/30\n",
      "235/235 [==============================] - 15s 64ms/step - loss: 0.2874 - accuracy: 0.9167 - val_loss: 0.1043 - val_accuracy: 0.9712\n",
      "Epoch 5/30\n",
      "235/235 [==============================] - 14s 59ms/step - loss: 0.2450 - accuracy: 0.9284 - val_loss: 0.0976 - val_accuracy: 0.9732\n",
      "Epoch 6/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.2168 - accuracy: 0.9371 - val_loss: 0.0836 - val_accuracy: 0.9762\n",
      "Epoch 7/30\n",
      "235/235 [==============================] - 14s 61ms/step - loss: 0.1985 - accuracy: 0.9418 - val_loss: 0.0700 - val_accuracy: 0.9792\n",
      "Epoch 8/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.1809 - accuracy: 0.9475 - val_loss: 0.0634 - val_accuracy: 0.9804\n",
      "Epoch 9/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.1655 - accuracy: 0.9516 - val_loss: 0.0609 - val_accuracy: 0.9815\n",
      "Epoch 10/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.1547 - accuracy: 0.9553 - val_loss: 0.0537 - val_accuracy: 0.9841\n",
      "Epoch 11/30\n",
      "235/235 [==============================] - 14s 57ms/step - loss: 0.1401 - accuracy: 0.9589 - val_loss: 0.0509 - val_accuracy: 0.9854\n",
      "Epoch 12/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.1326 - accuracy: 0.9606 - val_loss: 0.0568 - val_accuracy: 0.9842\n",
      "Epoch 13/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.1290 - accuracy: 0.9624 - val_loss: 0.0451 - val_accuracy: 0.9862\n",
      "Epoch 14/30\n",
      "235/235 [==============================] - 14s 59ms/step - loss: 0.1171 - accuracy: 0.9645 - val_loss: 0.0435 - val_accuracy: 0.9863\n",
      "Epoch 15/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.1114 - accuracy: 0.9665 - val_loss: 0.0450 - val_accuracy: 0.9855\n",
      "Epoch 16/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.1052 - accuracy: 0.9691 - val_loss: 0.0570 - val_accuracy: 0.9828\n",
      "Epoch 17/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.1064 - accuracy: 0.9681 - val_loss: 0.0388 - val_accuracy: 0.9883\n",
      "Epoch 18/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.1011 - accuracy: 0.9698 - val_loss: 0.0466 - val_accuracy: 0.9853\n",
      "Epoch 19/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0932 - accuracy: 0.9726 - val_loss: 0.0403 - val_accuracy: 0.9886\n",
      "Epoch 20/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0906 - accuracy: 0.9729 - val_loss: 0.0372 - val_accuracy: 0.9887\n",
      "Epoch 21/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.0922 - accuracy: 0.9722 - val_loss: 0.0362 - val_accuracy: 0.9879\n",
      "Epoch 22/30\n",
      "235/235 [==============================] - 14s 57ms/step - loss: 0.0864 - accuracy: 0.9739 - val_loss: 0.0330 - val_accuracy: 0.9886\n",
      "Epoch 23/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0838 - accuracy: 0.9744 - val_loss: 0.0407 - val_accuracy: 0.9869\n",
      "Epoch 24/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0833 - accuracy: 0.9749 - val_loss: 0.0336 - val_accuracy: 0.9889\n",
      "Epoch 25/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0802 - accuracy: 0.9762 - val_loss: 0.0350 - val_accuracy: 0.9899\n",
      "Epoch 26/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.0415 - val_accuracy: 0.9863\n",
      "Epoch 27/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0748 - accuracy: 0.9767 - val_loss: 0.0339 - val_accuracy: 0.9889\n",
      "Epoch 28/30\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.0739 - accuracy: 0.9776 - val_loss: 0.0346 - val_accuracy: 0.9899\n",
      "Epoch 29/30\n",
      "235/235 [==============================] - 14s 57ms/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 0.0318 - val_accuracy: 0.9899\n",
      "Epoch 30/30\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.0709 - accuracy: 0.9776 - val_loss: 0.0351 - val_accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a347ff1f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_datagen, initial_epoch=0, epochs=30,\n",
    "          validation_data=(mnist_test_images, mnist_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c53e9-31b1-4dd2-8097-7666977ebd90",
   "metadata": {},
   "source": [
    "#### Evaluating on MNIST test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c128e20-ba4b-4a08-adc6-521fea473f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.035125136375427246, 0.9896000027656555]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist_test_images, mnist_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a7309-80be-4f6f-9ee0-cea4629a7268",
   "metadata": {},
   "source": [
    "#### Evaluating on drawn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03c9a9cb-974f-46ba-be23-de85fd8ea931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 1s 3ms/step - loss: 0.1440 - accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14404082298278809, 0.9550480246543884]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(images, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
