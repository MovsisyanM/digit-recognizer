{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2>Multilabel classification - digit recognition</h2>\nBy <a href=\"https://movsisyan.info/\">Mher Movsisyan</a> and <a href=\"https://www.linkedin.com/in/tigran-avetisyan/\">Tigran Avetisyan</a>\n\n1. <a href=\"https://www.kaggle.com/movsisyanm/mnist-custom-dataset-cnn-classification#1\">Importing Tools and Data</a>\n2. <a href=\"https://www.kaggle.com/movsisyanm/mnist-custom-dataset-cnn-classification#2\">Joining Data</a>\n3. <a href=\"https://www.kaggle.com/movsisyanm/mnist-custom-dataset-cnn-classification#3\">Creating Custom Layer and Callback</a>\n4. <a href=\"https://www.kaggle.com/movsisyanm/mnist-custom-dataset-cnn-classification#4\">Importing Tools and Data</a>\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"1\">1 - Importing Tools and Data</h2>","metadata":{}},{"cell_type":"code","source":"! pip install keract\n\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom keras import backend as K\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nimport matplotlib.patches as patches\nfrom skimage.filters import threshold_otsu\nfrom keras.optimizers import RMSprop, SGD, Adam\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keract import get_activations, display_activations\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\nfrom keras.layers.experimental.preprocessing import RandomTranslation, RandomRotation, RandomWidth, RandomHeight, RandomZoom, Resizing\nfrom keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D, BatchNormalization, Reshape, GlobalAveragePooling2D, LeakyReLU, Layer, Concatenate, Input\n\nseed = 173\nnp.random.seed(seed)\ntf.random.set_seed(seed)\n\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:16.297995Z","iopub.execute_input":"2021-08-29T16:07:16.298342Z","iopub.status.idle":"2021-08-29T16:07:33.297025Z","shell.execute_reply.started":"2021-08-29T16:07:16.298314Z","shell.execute_reply":"2021-08-29T16:07:33.295554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/digits-mini-dataset-5500/drawings_non_binary.csv\")\nmnist = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:33.298615Z","iopub.execute_input":"2021-08-29T16:07:33.298974Z","iopub.status.idle":"2021-08-29T16:07:36.929053Z","shell.execute_reply.started":"2021-08-29T16:07:33.298937Z","shell.execute_reply":"2021-08-29T16:07:36.928049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"2\">2 - Joining Data</h2>","metadata":{}},{"cell_type":"code","source":"joint = pd.DataFrame(mnist.iloc[:, 1:].to_numpy())\njoint[\"label\"] = mnist.label\njointDf = pd.DataFrame(np.concatenate((joint, df), axis=0)).rename({784: \"label\"}, axis=1).sample(frac=1, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:36.931158Z","iopub.execute_input":"2021-08-29T16:07:36.931516Z","iopub.status.idle":"2021-08-29T16:07:37.521831Z","shell.execute_reply.started":"2021-08-29T16:07:36.931476Z","shell.execute_reply":"2021-08-29T16:07:37.52078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making sure the classes are balanced","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = joint.label);","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:37.523558Z","iopub.execute_input":"2021-08-29T16:07:37.524004Z","iopub.status.idle":"2021-08-29T16:07:37.707666Z","shell.execute_reply.started":"2021-08-29T16:07:37.523959Z","shell.execute_reply":"2021-08-29T16:07:37.706928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One-hot encoding labels","metadata":{}},{"cell_type":"code","source":"y = to_categorical(jointDf.label)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:37.708876Z","iopub.execute_input":"2021-08-29T16:07:37.709248Z","iopub.status.idle":"2021-08-29T16:07:37.715584Z","shell.execute_reply.started":"2021-08-29T16:07:37.709209Z","shell.execute_reply":"2021-08-29T16:07:37.714832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extracting inference and holdout datasets","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(jointDf.iloc[:,:-1], y, train_size=0.9, random_state=seed) # no need to stratify for large balanced datasets\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:37.716852Z","iopub.execute_input":"2021-08-29T16:07:37.717208Z","iopub.status.idle":"2021-08-29T16:07:37.960318Z","shell.execute_reply.started":"2021-08-29T16:07:37.717166Z","shell.execute_reply":"2021-08-29T16:07:37.959288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Displaying a random observation","metadata":{}},{"cell_type":"code","source":"plt.imshow(np.array(x_test.sample(1, random_state=seed)).reshape(28, 28));","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:37.961757Z","iopub.execute_input":"2021-08-29T16:07:37.962128Z","iopub.status.idle":"2021-08-29T16:07:38.101087Z","shell.execute_reply.started":"2021-08-29T16:07:37.96209Z","shell.execute_reply":"2021-08-29T16:07:38.100141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"3\">3 - Creating Custom Layer and Callback</h2>","metadata":{}},{"cell_type":"markdown","source":"Creating a custom callback for the convolutional neural network.   \nThis callback works like the inverse of ReduceLROnPlateau. In case the model converges to a local extremum, the GateOfLearning callback kicks the learning rate up to help it overcome barriers and hopefully converge to a global extremum.\n  \n  \nGuess where the name 'GateOfLearning' is from :D","metadata":{}},{"cell_type":"code","source":"class GateOfLearning(Callback):\n    \"\"\"Increases learning rate when stuck at extrema, a friend to ReduceLROnPlateau, ModelCheckpoint callbacks.\\n\n\n    \\n\n    Args:\\n\n        `monitor`: quantity to be monitored.\\n\n        `factor`: factor by which the learning rate will be reduced. Must be multitudes greater than that of the ReduceLROnPlateau\\n\n            `new_lr = lr * factor`.\\n\n        `patience`: number of epochs with no improvement after which learning rate will be increased. Must be greater \\\n            than that of the ReduceLROnPlateau `(6 by default)`\\n\n        `verbose`: int. 0: quiet, 1: update messages. `(1 by default)`\\n\n        `mode`: one of `{'min', 'max'}`. In `'min'` mode, the learning rate will be increased when the quantity\\\n             monitored has stopped decreasing; in `'max'` mode it will be increased when the quantity monitored has stopped increasing.\\n\n        `cooldown`: number of epochs to wait before resuming normal operation afterlr has been reduced. `(0 by default)`\\n\n        `max_lr`: upper bound on the learning rate. `(initial value * 50 by default)`\\n\n    \"\"\"\n\n    def __init__(self, monitor=\"val_loss\", factor=15.0, patience=6, verbose=1, mode=\"min\", cooldown=0, max_lr=999):\n        # Sanity check\n        if factor <= 1.0:\n            raise ValueError(\n                \"GateOfLearning does not support a factor <= 1.0.\")\n\n        if mode not in [\"min\", \"max\"]:\n            raise ValueError(\n                f\"GateOfLearning does not support a mode '{mode}'. Use 'min' or 'max' instead.\")\n\n        # Init\n        super(GateOfLearning, self).__init__()\n        self.monitor = monitor\n        self.factor = factor\n        self.patience = patience\n        self.verbose = verbose\n        self.objective = min if mode == \"min\" else max\n        self.cooldown = cooldown\n        self.max_lr = max_lr\n\n        self.backup = (monitor, factor, patience,\n                       verbose, mode, cooldown, max_lr)\n\n        self.observations = []\n        self.lr_history = []\n        self.last_opened = 0\n\n    def _reset(self):\n        \"\"\"Reset state\"\"\"\n        self.monitor, self.factor, self.patience, self.verbose, self.mode, self.cooldown, self.max_lr = self.backup\n\n        self.observations = []\n        self.lr_history = []\n        self.last_opened = 0\n\n    def on_train_begin(self, logs=None):\n        \"\"\"Training start handler\"\"\"\n        self._reset()\n\n    def open_gate(self):\n        \"\"\"Increases learning rate\"\"\"\n        new_lr = self.lr_history[-1] * self.factor\n\n        assert new_lr > self.lr_history[-1], f\"old: {self.lr_history[-1]}, new: {new_lr}\"\n\n        if new_lr > self.max_lr:\n\n            if self.verbose:\n                print(\"Learning rate diverged. You can solve this problem by using a faster ReduceLROnPlateau, \\\n                    a smaller factor, or a bigger patience/cooldown. Make sure the objective is appropriate.\")\n        else:\n            old_lr = float(self.model.optimizer.learning_rate)\n            self.model.optimizer.learning_rate = new_lr\n            if self.verbose:\n                print(\n                    f\"\\nGateOfLearning: Learning rate increased from {old_lr} to {float(self.model.optimizer.learning_rate)}\")\n\n    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Epoch end handler\"\"\"\n        # Log learning rate.\n        self.lr_history.append(logs[\"lr\"])\n\n        # Set the maximum learning rate to the initial or otherwise specified maximum learning rate\n        if len(self.lr_history) <= 1:\n            self.max_lr = min(self.max_lr, 50 * self.lr_history[0])\n\n        # Check if the metric is reported, otherwise use default metrics.\n        if self.monitor not in logs.keys():\n            initMetric = self.monitor\n            self.monitor = \"val_loss\" if \"val_loss\" in logs.keys() else \"loss\"\n            if self.verbose:\n                print(\n                    f\"\\nGateOfLearning: The '{initMetric}' metric was never reported. Using '{self.monitor}' instead.\\n\")\n\n        # Log metric\n        self.observations.append(logs[self.monitor])\n\n        # Check if it is too early for an opening\n        if len(self.observations) <= self.patience:\n            return\n\n        # Check if there is no improvement\n        if self.objective(self.observations[-self.patience:]) == self.observations[-self.patience]:\n            if epoch - self.last_opened > self.cooldown:\n                self.open_gate()\n                self.last_opened = epoch\n                self.observations = [self.observations[-self.patience]]","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-29T16:07:38.10361Z","iopub.execute_input":"2021-08-29T16:07:38.104091Z","iopub.status.idle":"2021-08-29T16:07:38.12071Z","shell.execute_reply.started":"2021-08-29T16:07:38.10405Z","shell.execute_reply":"2021-08-29T16:07:38.119986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Singularity Extractor is a layer that explores the feature space taking into account the grid-like structure of it. It accentuates non-uniform feature localities that otherwise a convolutional block might miss. An example of this would be the array `[10, 10, 2, 10, 10]`, where the feature in the middle differs from the rest significantly, this significant difference would be accentuated by the singularity extractor and it would output an array that would look like this: `[0.13, 0.08, 0.94, 0.08, 0.13]`","metadata":{}},{"cell_type":"code","source":"class SingularityExtractor2D(Layer):\n    \"\"\"\n    Accentuates pixels that differ from its surrounding pixels. \n    \"\"\"\n\n    def __init__(self, degree=6, kernel_size=3, padding=\"SYMMETRIC\", margin=1, **kwargs):\n        if not ((kernel_size % 2) and kernel_size >= 3 and isinstance(kernel_size, int)):\n            raise ValueError(\"kernel_size: value must be odd, >= 3\")\n\n        if not (margin >= 1 and isinstance(margin, int)):\n            raise ValueError(\"margin: must be integer >= 1\")\n\n        if padding not in [\"CONSTANT\", \"SYMMETRIC\", \"REFLECT\"]:\n            raise ValueError(\n                \"padding: must be one of ['CONSTANT', 'SYMMETRIC', 'REFLECT']\")\n\n        self.degree = degree\n        self.kernel_size = kernel_size\n        self.padding = padding\n        self.margin = margin\n\n        self.radius = int((kernel_size - 1)/2)\n        \n        if \"trainable\" in kwargs.keys():\n            super(SingularityExtractor2D, self).__init__(**kwargs)\n        else:\n            super(SingularityExtractor2D, self).__init__(trainable = False, **kwargs)\n\n    # region Keras api\n\n    def build(self, input_shape):\n        if len(input_shape) != 4:\n            raise ValueError(\"input must be 4D (batch_size, x, y, channels)\")\n\n        super(SingularityExtractor2D, self).build(input_shape)\n\n        # Lazy load conv kernel\n        self.ones = tf.ones((self.kernel_size, self.kernel_size, input_shape[-1], input_shape[-1]))\n\n    def get_config(self):\n        \"\"\"Layer to dict = serializability\"\"\"\n\n        config = super(SingularityExtractor2D, self).get_config()\n        config[\"degree\"] = self.degree\n        config[\"kernel_size\"] = self.kernel_size\n        config[\"padding\"] = self.padding\n        config[\"margin\"] = self.margin\n        config[\"dtype\"] = self.dtype\n\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(\n            config[\"degree\"],\n            config[\"kernel_size\"],\n            config[\"padding\"],\n            config[\"margin\"],\n            dtype=config[\"dtype\"]\n        )\n\n    def call(self, input_data):\n        return self.extract(input_data, \"keras\")\n\n    # endregion Keras api\n\n    # region Scikit api\n\n    def fit(self, x, *args, **kwargs):\n        if len(x.shape) != 4:\n            raise ValueError(\n                \"input must be 4D (number_of_observations, x, y, 1)\")\n\n    def transform(self, input_data, *args, **kwargs):\n        return self.extract(input_data, \"sk\")\n\n    # endregion Scikit api\n\n    def extract(self, input_data, api):\n        if api == \"sk\":\n            self.extract(input_data, \"keras\").numpy()\n        else:\n            # Pad the incoming tensor\n            matpad = tf.pad(input_data, [\n                [0, 0],\n                [self.radius, self.radius],\n                [self.radius, self.radius],\n                [0, 0]\n            ], mode=self.padding)\n\n            # Sum all the pixels in the kernel\n            conv = tf.nn.convolution(matpad, self.ones, 1, padding=\"SAME\")\n\n            # Calculate the change in shape\n            mrgn_0 = int((conv.shape[1] - input_data.shape[1])/2) + self.margin\n            mrgn_1 = int((conv.shape[2] - input_data.shape[2])/2) + self.margin\n\n            # Select appropriate regions\n            selection_conv = conv[:, mrgn_0:-mrgn_0, mrgn_1:-mrgn_1, :]\n            selection_input = input_data[:, self.margin:-\n                                         self.margin, self.margin:-self.margin, :]\n\n            # Compute the output\n            return ((selection_conv - selection_input) / selection_conv) ** self.degree\n","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:07:38.122025Z","iopub.execute_input":"2021-08-29T16:07:38.122364Z","iopub.status.idle":"2021-08-29T16:07:38.141647Z","shell.execute_reply.started":"2021-08-29T16:07:38.122331Z","shell.execute_reply":"2021-08-29T16:07:38.140786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 id=\"4\">4 - Building the model:</h2>","metadata":{}},{"cell_type":"markdown","source":"Randomly change the width, position and zoom of the training batch.","metadata":{}},{"cell_type":"code","source":"class PreprocessingBlock(Layer):\n    \"\"\"Preprocessing block (width, translation, zoom, seed=173)\"\"\"\n\n    def __init__(self, width, translation, zoom, seed=173):\n        super(PreprocessingBlock, self).__init__()\n        self.w, self.t, self.z, self.s = width, translation, zoom, seed\n        self.reshape = Reshape((28, 28, 1))\n        self.width = RandomWidth(width, seed=seed, interpolation=\"bicubic\")\n        self.translation = RandomTranslation(\n            *translation, seed=seed, fill_mode=\"constant\", fill_value=0)\n        self.zoom = RandomZoom(*zoom, seed=seed)\n        self.resize = Resizing(28, 28, interpolation=\"bicubic\")\n\n    def call(self, input_data, training=None):\n        x = self.reshape(input_data)\n\n        if training:\n            x = self.width(x)\n            x = self.translation(x)\n            x = self.zoom(x)\n            x = self.resize(x)\n\n        return x\n    \n    def get_config(self):\n        config = super(PreprocessingBlock, self).get_config()\n        config[\"width\"] = self.w\n        config[\"translation\"] = self.t\n        config[\"zoom\"] = self.z\n        config[\"seed\"] = self.s\n        \n        return config\n        \n    @classmethod\n    def from_config(cls, config):\n        cls(**config)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:08:11.632008Z","iopub.execute_input":"2021-08-29T16:08:11.632433Z","iopub.status.idle":"2021-08-29T16:08:11.644276Z","shell.execute_reply.started":"2021-08-29T16:08:11.632392Z","shell.execute_reply":"2021-08-29T16:08:11.64336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(Layer):\n    \"\"\"A block of convolutional layers\"\"\"\n\n    def __init__(self, units, kernel_size, depth, pool=False, seed=173):\n        super(ConvBlock, self).__init__()\n        self.units = units\n        self.kernel_size = kernel_size\n        self.depth = depth\n        self.pool = pool\n        self.seed = seed\n        self.layers = []\n\n        for i in range(depth - 1):\n            self.layers.append(\n                Conv2D(units, kernel_size=kernel_size, padding=\"same\", activation=\"relu\"))\n            self.layers.append(BatchNormalization(axis=1))\n\n        if pool:\n            self.layers.append(\n                Conv2D(units, kernel_size=kernel_size, padding=\"same\", activation=\"relu\"))\n            self.layers.append(MaxPool2D())\n        else:\n            self.layers.append(Conv2D(\n                units, kernel_size=kernel_size, padding=\"same\", strides=2, activation=\"relu\"))\n\n    def call(self, input_data):\n        out = input_data\n        for layer in self.layers:\n            out = layer(out)\n        return out\n    \n    def get_config(self):\n        config = super(ConvBlock, self).get_config()\n        config[\"units\"] = self.units\n        config[\"kernel_size\"] = self.kernel_size\n        config[\"depth\"] = self.depth\n        config[\"pool\"] = self.pool\n        config[\"seed\"] = self.seed\n        \n        return config\n        \n    @classmethod\n    def from_config(cls, config):\n        cls(**config)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:08:17.150254Z","iopub.execute_input":"2021-08-29T16:08:17.150574Z","iopub.status.idle":"2021-08-29T16:08:17.160631Z","shell.execute_reply.started":"2021-08-29T16:08:17.150545Z","shell.execute_reply":"2021-08-29T16:08:17.159509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(seed=173):\n    \"\"\"Generate MSXCN\"\"\"\n    \n    x = Input((28 * 28))\n    y = PreprocessingBlock(0.18, (0.14, 0.2), ((-0.05, -0.1), (-0.05, -0.02)), seed=seed)(x)\n\n\n    # Convolutional chain\n    y_0_0 = ConvBlock(32, 5, 2, True, seed=seed)(y)\n    y_0 = BatchNormalization(axis=1)(y_0_0) # Some papers suggest to stay away from\n    y_0 = Dropout(0.3, seed=seed)(y_0)    # using batch-norm and dropout together\n                                          # https://link.springer.com/article/10.1007/s11042-019-08453-9\n        \n    y_0 = ConvBlock(64, 5, 2, True, seed=seed)(y_0)\n    y_0 = BatchNormalization(axis=1)(y_0)\n    y_0 = Dropout(0.3, seed=seed)(y_0)\n\n    \n    y_0 = ConvBlock(128, 5, 2, True, seed=seed)(y_0)\n    y_0 = GlobalAveragePooling2D()(y_0)\n    y_0 = Flatten()(y_0)\n    y_0 = BatchNormalization(axis=1)(y_0)\n    y_0 = Dropout(0.4, seed=seed)(y_0)\n    \n    \n    # Singularity Extractor chain 1\n    y_1 = SingularityExtractor2D(6, 5, margin=2)(y)\n    y_1 = Dense(16, activation=\"relu\")(y_1)\n    y_1 = Flatten()(y_1)\n    y_1 = BatchNormalization(axis=1)(y_1)\n    \n#     # Singularity Extractor chain 2\n#     y_2 = SingularityExtractor2D(6, 3, margin=1)(y_0_0)\n#     y_2 = Dense(16, activation=\"relu\")(y_2)\n#     y_2 = Flatten()(y_2)\n#     y_2 = BatchNormalization(axis=1)(y_2)\n\n\n\n    # Cognitive block\n    y = Concatenate()([y_0, y_1])\n    y = Dense(1024)(y)\n    y = LeakyReLU(0.1)(y)\n    y = BatchNormalization(axis=1)(y)\n    y = Dropout(0.5, seed=seed)(y)\n\n    y = Dense(2048, activation=\"tanh\")(y)\n    y = BatchNormalization(axis=1)(y)\n    y = Dropout(0.65, seed=seed)(y)\n\n    y = Dense(10, activation=\"softmax\")(y)\n\n    opt = RMSprop(learning_rate = 0.002, decay = 0)\n    model = tf.keras.Model(x, y)\n    model.compile(opt, \"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    return model\n    \nlr_cut = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=3, verbose=1, min_lr=0.000000001, mode=\"min\", cooldown=3)\nquicksave = ModelCheckpoint(monitor=\"val_loss\", filepath=\"data/checkpoint.hdf5\", verbose=1, save_best_only=True)\nlr_boost = GateOfLearning(monitor=\"val_loss\", factor=100, patience = 17, mode = \"min\", cooldown=19)\n\nmodel = get_model(seed)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:42:43.920412Z","iopub.execute_input":"2021-08-29T16:42:43.920891Z","iopub.status.idle":"2021-08-29T16:42:44.226328Z","shell.execute_reply.started":"2021-08-29T16:42:43.920826Z","shell.execute_reply":"2021-08-29T16:42:44.225466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"/device:GPU:0\"):\n    hist = model.fit(x_train/255, y_train, epochs=75, batch_size=128, validation_data = (x_test/255, y_test), shuffle=True, callbacks=[lr_cut, quicksave, lr_boost])","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:27:22.208354Z","iopub.execute_input":"2021-08-29T16:27:22.208664Z","iopub.status.idle":"2021-08-29T16:37:30.261026Z","shell.execute_reply.started":"2021-08-29T16:27:22.208634Z","shell.execute_reply":"2021-08-29T16:37:30.260222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: in the context of the Digit Recognition competition, we are only using a validation set to evaluate the model","metadata":{}},{"cell_type":"code","source":"plt.plot(hist.history[\"accuracy\"][6:]);\nplt.plot(hist.history[\"val_accuracy\"][6:]);\nplt.legend([\"accuracy\", \"val accuracy\"]);","metadata":{"execution":{"iopub.status.busy":"2021-08-29T16:42:09.038915Z","iopub.execute_input":"2021-08-29T16:42:09.039247Z","iopub.status.idle":"2021-08-29T16:42:09.203735Z","shell.execute_reply.started":"2021-08-29T16:42:09.039215Z","shell.execute_reply":"2021-08-29T16:42:09.202781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist.history[\"loss\"][6:]);\nplt.plot(hist.history[\"val_loss\"][6:]);\nplt.axvline(np.argmin(hist.history[\"val_loss\"][6:]), color=\"green\")\nplt.legend([\"loss\", \"val loss\"]);","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:44:29.69315Z","iopub.execute_input":"2021-08-29T15:44:29.693469Z","iopub.status.idle":"2021-08-29T15:44:29.909703Z","shell.execute_reply.started":"2021-08-29T15:44:29.693442Z","shell.execute_reply":"2021-08-29T15:44:29.908925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"data/checkpoint.hdf5\")\nmodel.evaluate(x_test/255, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:28:43.331327Z","iopub.execute_input":"2021-08-29T15:28:43.331646Z","iopub.status.idle":"2021-08-29T15:28:44.087267Z","shell.execute_reply.started":"2021-08-29T15:28:43.331616Z","shell.execute_reply":"2021-08-29T15:28:44.086503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_train/255, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:28:45.822449Z","iopub.execute_input":"2021-08-29T15:28:45.822758Z","iopub.status.idle":"2021-08-29T15:28:51.009092Z","shell.execute_reply.started":"2021-08-29T15:28:45.822729Z","shell.execute_reply":"2021-08-29T15:28:51.008318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(x_test/255, batch_size=128, verbose=0), axis=1)\ny_true = np.argmax(y_test, axis=1)\nprint(classification_report(y_true, y_pred))\nprint(\"\\n------------------------------\\n\")\nprint(confusion_matrix(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:28:55.929313Z","iopub.execute_input":"2021-08-29T15:28:55.929637Z","iopub.status.idle":"2021-08-29T15:28:56.340541Z","shell.execute_reply.started":"2021-08-29T15:28:55.929609Z","shell.execute_reply":"2021-08-29T15:28:56.339576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at the labels that were mislabeled","metadata":{}},{"cell_type":"code","source":"mislabeled = y_pred != y_true\naxes=[]\nfig=plt.figure(figsize=(12,9))\n\nfor row in range(3):\n    for col in range(6):\n        axes.append(fig.add_subplot(3, 6, row * 6 + col + 1))\n        subplot_title = f\"Prediction: {y_pred[mislabeled][row * 6 + col]}\\nActual: {y_true[mislabeled][row * 6  + col]}\"\n        axes[-1].set_title(subplot_title)  \n        plt.imshow(np.array(x_test[mislabeled].reset_index(drop=True).loc[row * 6 + col, :]).reshape(28, 28))\nfig.tight_layout()    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:28:58.259322Z","iopub.execute_input":"2021-08-29T15:28:58.259678Z","iopub.status.idle":"2021-08-29T15:29:00.435435Z","shell.execute_reply.started":"2021-08-29T15:28:58.259649Z","shell.execute_reply":"2021-08-29T15:29:00.434392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig.savefig(\"mislabeled.png\")","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:29:16.714051Z","iopub.execute_input":"2021-08-29T15:29:16.714378Z","iopub.status.idle":"2021-08-29T15:29:16.986816Z","shell.execute_reply.started":"2021-08-29T15:29:16.714348Z","shell.execute_reply":"2021-08-29T15:29:16.986012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"final.h5\") # Saving the model","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:29:22.186514Z","iopub.execute_input":"2021-08-29T15:29:22.18687Z","iopub.status.idle":"2021-08-29T15:29:22.28805Z","shell.execute_reply.started":"2021-08-29T15:29:22.18684Z","shell.execute_reply":"2021-08-29T15:29:22.287232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_predict = pd.read_csv(\"../input/digit-recognizer/test.csv\")\nx_test_predict","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:29:28.451221Z","iopub.execute_input":"2021-08-29T15:29:28.451573Z","iopub.status.idle":"2021-08-29T15:29:30.660778Z","shell.execute_reply.started":"2021-08-29T15:29:28.451526Z","shell.execute_reply":"2021-08-29T15:29:30.659979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(x_test_predict/255)\npreds = np.argmax(preds, axis=1)\npreds = pd.DataFrame(preds)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:29:31.530694Z","iopub.execute_input":"2021-08-29T15:29:31.53104Z","iopub.status.idle":"2021-08-29T15:29:33.980883Z","shell.execute_reply.started":"2021-08-29T15:29:31.531008Z","shell.execute_reply":"2021-08-29T15:29:33.979977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[\"ImageId\"] = np.arange(1, 28001)\npreds[\"Label\"] = preds[0]\npreds = preds.drop(0, axis=1).set_index(\"ImageId\", drop=True)\npreds","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:29:40.796974Z","iopub.execute_input":"2021-08-29T15:29:40.797282Z","iopub.status.idle":"2021-08-29T15:29:40.816489Z","shell.execute_reply.started":"2021-08-29T15:29:40.797253Z","shell.execute_reply":"2021-08-29T15:29:40.815741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-29T15:29:45.514271Z","iopub.execute_input":"2021-08-29T15:29:45.514592Z","iopub.status.idle":"2021-08-29T15:29:45.573946Z","shell.execute_reply.started":"2021-08-29T15:29:45.514561Z","shell.execute_reply":"2021-08-29T15:29:45.573158Z"},"trusted":true},"execution_count":null,"outputs":[]}]}